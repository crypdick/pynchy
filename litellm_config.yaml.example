# LiteLLM Proxy Configuration
# ============================
# Copy to litellm_config.yaml and fill in your API keys.
# This file is the single source of truth for LLM routing â€” pynchy reads
# it but never modifies it.
#
# Docs: https://docs.litellm.ai/docs/proxy/configs
#
# To enable: set gateway.litellm_config = "litellm_config.yaml" in config.toml

# ---------------------------------------------------------------------------
# Model deployments
# ---------------------------------------------------------------------------
# Multiple entries with the same model_name are load-balanced automatically.
# The model_name must match what the agent sends (e.g. claude-opus-4-6).

model_list:
  # --- Anthropic account 1 (primary) ---
  - model_name: claude-opus-4-6
    litellm_params:
      model: anthropic/claude-opus-4-6
      api_key: "sk-ant-api03-PRIMARY-KEY-HERE"
      max_budget: 10.0  # USD per month
      budget_duration: 7d  # 1s, 1m, 1h, 1d, 1mo
      custom_llm_provider: anthropic  # Required for budget tracking
    model_info:
      id: anthropic-primary
      tags: ["primary"]  # Optional: for filtering/reporting

  # --- Anthropic account 2 (secondary) ---
  - model_name: claude-opus-4-6
    litellm_params:
      model: anthropic/claude-opus-4-6
      api_key: "sk-ant-api03-SECONDARY-KEY-HERE"
      max_budget: 50.0
      budget_duration: 7d
      custom_llm_provider: anthropic
    model_info:
      id: anthropic-secondary
      tags: ["secondary"]

  # --- OpenAI (optional) ---
  # - model_name: gpt-4o
  #   litellm_params:
  #     model: openai/gpt-4o
  #     api_key: "sk-proj-YOUR-OPENAI-KEY"
  #     max_budget: 10.0
  #     budget_duration: 30d
  #     custom_llm_provider: openai
  #   model_info:
  #     id: openai-primary
  #     tags: ["primary"]

  # --- Add more models as needed ---
  # Agents will get an error if they request a model not listed here.
  #
  # - model_name: claude-sonnet-4-5-20250514
  #   litellm_params:
  #     model: anthropic/claude-sonnet-4-5-20250514
  #     api_key: "sk-ant-api03-PRIMARY-KEY-HERE"
  #     max_budget: 5.0
  #     budget_duration: 7d
  #     custom_llm_provider: anthropic
  #   model_info:
  #     id: anthropic-primary-sonnet
  #     tags: ["primary", "sonnet"]

# ---------------------------------------------------------------------------
# Router settings
# ---------------------------------------------------------------------------
router_settings:
  # How to distribute requests across deployments with the same model_name.
  # Options: simple-shuffle, least-busy, usage-based-routing,
  #          latency-based-routing, cost-based-routing
  routing_strategy: usage-based-routing

  # Retry failed requests on a different deployment
  num_retries: 2
  timeout: 300

  # Cool down a deployment for 60s after 3 consecutive failures
  allowed_fails: 3
  cooldown_time: 60

  # Provider-level budget caps (combined across all keys for that provider).
  # Requires the PostgreSQL sidecar (started automatically by pynchy).
  # For per-key budgets, use max_budget in litellm_params above.
  #
  # provider_budget_config:
  #   anthropic:
  #     budget_limit: 200.0   # USD
  #     time_period: 30d
  #   openai:
  #     budget_limit: 50.0
  #     time_period: 30d

# ---------------------------------------------------------------------------
# General settings
# ---------------------------------------------------------------------------
general_settings:
  # Master key is dynamically generated at runtime by pynchy and passed via env var.
  # Do NOT hardcode it here.
  master_key: os.environ/LITELLM_MASTER_KEY

  # Max parallel requests across all models
  global_max_parallel_requests: 50

  # Public routes: Make routes accessible without auth
  # Only use this if LiteLLM is behind a secure network (e.g., Tailnet, VPN).
  # This allows the UI dashboard and API to be accessed without auth tokens.
  #
  # public_routes:
  #   - "/*"  # All routes public (only use on private networks!)

  # UI credentials are set in config.toml under [gateway]:
  #   ui_username = "admin"
  #   ui_password = "your-secure-password"
  # They're passed to LiteLLM as UI_USERNAME and UI_PASSWORD env vars.
